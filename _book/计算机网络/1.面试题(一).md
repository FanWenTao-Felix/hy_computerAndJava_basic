## 一 OSI与TCP/IP各层的结构与功能,都有哪些协议?

学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。

![五层体系结构](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/五层体系结构.png)

结合互联网的情况，自上而下地，非常简要的介绍一下各层的作用。

### 1.1 应用层

**应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如**域名系统DNS**，支持万维网应用的 **HTTP协议**，支持电子邮件的 **SMTP协议**等等。我们把应用层交互的数据单元称为报文。

**域名系统**

> 域名系统(Domain Name System缩写 DNS，Domain Name被译为域名)是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。（百度百科）例如：一个公司的 Web 网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM 公司的域名是 www.ibm.com、Oracle 公司的域名是 www.oracle.com、Cisco公司的域名是 www.cisco.com 等。

**HTTP协议**

> 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。（百度百科）

### 1.2 运输层

**运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务**。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。

**运输层主要使用以下两种协议:**

1. **传输控制协议 TCP**（Transmission Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。
2. **用户数据协议 UDP**（User Datagram Protocol）--提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。

**TCP 与 UDP 的对比见问题三。**

### 1.3 网络层

**在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 **IP 数据报** ，简称 **数据报**。

这里要注意：**不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混**。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。

这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.

互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Protocol）和许多路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**。

### 1.4 数据链路层

**数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。** 在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。
控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

### 1.5 物理层

在物理层上所传送的数据单位是比特。
 **物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。** 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。

在互联网使用的各种协中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的TCP/IP并不一定单指TCP和IP这两个具体的协议，而往往表示互联网所使用的整个TCP/IP协议族。

## 二 TPC/IP协议族?

### 1.什么是TCP/IP

**TCP/IP是一套用于网络通信的协议集合或者系统。TCP/IP协议模型就有OSI模型分为7层。但其实一般我们所谈到的都是四层的TCP/IP协议栈。**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170321140028195-1597402495147)

**网络接口层：主要是指一些物理层层次的接口，比如电缆等**

**网络层：提供了独立于硬件的逻辑寻址，实现物理地址和逻辑地址的转换。网络层协议包括IP协议（网际协议），ICMP协议（互联网控制报文协议），IGMP协议(Internet组协议管理)**

**传输层：为网络提供了流量控制，错误控制和确认服务。传输层有两个互不相同的传输协议：TCP（传输控制协议）、UDP（用户数据报协议）**

**应用层：为文件传输，网络排错和Internet操作提供具体的程序应用**

### **2.数据包**

**在TCP/IP协议中数据由上至下将数据封装成包，然后再由下至上的拆包。那么数据又是怎么打包的呢？** 

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170402144442694.png)

**在装包的时候，每一层都会增加一些信息用于传输，这部分信息叫做报头。当上层数据到达本层的时候，会将数据加上报头打包在一起形成新的数据包继续往下一层传递。拆包的时候就是反着来了，就像俄罗斯套娃一样，拆完最外面一层得到需要的报头，向上传递。**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215130840163.png)

 



 

### 1.应用层

**应用层作为TCP/IP协议的最上层，其实是我们接触最多的。**

**由于在传输层的传输协议大致分成了TCP和UDP，所以在应用层对应的协议也就分成了两部分。**

 

#### 运行在TCP协议上的协议：

- HTTP（Hypertext Transfer Protocol，超文本传输协议），主要用于普通浏览。
- HTTPS（Hypertext Transfer Protocol over Secure Socket Layer, or HTTP over SSL，安全超文本传输协议）,HTTP协议的安全版本。
- FTP（File Transfer Protocol，文件传输协议），由名知义，用于文件传输。
- POP3（Post Office Protocol, version 3，邮局协议），收邮件用。
- SMTP（Simple Mail Transfer Protocol，简单邮件传输协议），用来发送电子邮件。
- TELNET（Teletype over the Network，网络电传），通过一个终端（terminal）登陆到网络。
- SSH（Secure Shell，用于替代安全性差的TELNET），用于加密安全登陆用。

#### 运行在UDP协议上的协议：

- BOOTP（Boot Protocol，启动协议），应用于无盘设备。
- NTP（Network Time Protocol，网络时间协议），用于网络同步。
- DHCP（Dynamic Host Configuration Protocol，动态主机配置协议），动态配置IP地址。

**Http协议的工作流程**

**一次Http操作称为一个事务，其整个工作流程如下：**

**1）地址解析**

**比如客户端浏览器请求浏览页面：www.baidu.com。其实这是一个默认路径，因为平常默认会省略协议名、端口号，访问主页的时候路径也会省略，所以完整路径写法是http://www.baidu.com:80/index.html。这就是我们常说的URL统一资源定位符，用来定位我们访问资源在服务器上的位置。**

**从这个URL中可以分解出协议名、主机名、端口号、访问对象的路径**

- 协议名：http
- 主机名：[www.baidu.com](http://www.baidu.com/index.html)
- 端口号：80（http协议的默认端口）
- 路径：[/index.html](http://www.baidu.com/index.html)

**在这时候需要域名系统DNS协议解析域名，得到主机的ip。**

**2）封装http请求数据包**

**将以上部分（我们想要访问的服务器页面资源）结合自己的本机信息生成一个请求数据报文，封装成一个HTTP请求数据包。至于http的请求数据报文什么样，如下：**

#### HTTP简介：

> 
>
> ## HTTP简介：
>
>  
>
> 1.HTTP是Hyper Text Transfer Protocol的缩写（超文本传输协议），是用于从万维网（WWW:World Wide Web）服务器传输超文本到本地浏览器的传送协议。你问我什么是[超文本](https://baike.baidu.com/item/%E8%B6%85%E6%96%87%E6%9C%AC/2832422?fr=aladdin)？
>
> 2.是基于TCP/IP通信协议来传递数据的（HTML文件，图片文件，查询结果等）。
>
> 3.HTTP基于C/S架构模型（客户端/服务端），通过一个可靠的链接来交换信息。浏览器作为HTTP客户端向WEB服务器发送所有的请求，WEB服务器收到请求以后，向HTTP客户端发送响应消息。
>
> ##  
>
> ## 特点：
>
>  
>
> 1.简单快速：客户端每次向服务器发出请求的时候只需要传递请求方法和路径。常用方法比如：GET，POST，每种方法规定了客户端和服务端联系方式的不同。由于HTTP协议简单，使得HTTP服务器程序规模小，因此通信速度较快。
>
> 2.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type标记。
>
> 4.无状态：HTTP协议是无状态协议。无状态是指协议对事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。
>
> ##  
>
> ## HTTP请求报文：
>
>  
>
> ### **HTTP请求报文由三部分组成**
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170707143243946.jfif)
>
> **请求行由（123）组成：1是请求方法；2是url地址，它和报文头的Host属性组成完整的请求URL；3是协议名称和版本号。**
>
> **请求头（4）：是HTTP的报文头，报文头包含若干个属性，格式均为"属性名：属性值"，服务端由此获得客户端的信息。与缓存有关的信息都放在头部（header）。（key:value的形式，一个key对应一个value，一个key对应多个value，但是其实一个key也可以对应多个value。结果区别就是aa：bb和aa：bb，cc）**
>
> **请求体（5）：它将一个页面表单中的组件值通过param1=value1&param2=value2的键值对形式编码成一个格式化串，它承载着多个请求参数的数据。**
>
>  
>
> > **HTTP请求报文属性：**
> >
> > **Accept** ：请求报文通过Accept属性告诉服务器，大哥我就只能接受这个类型的响应（比如纯文本）,你发图片我就GG了!(当然了，Accept属性的值可以为一个或者多个[MIME](https://baike.baidu.com/item/MIME/2900607?fr=aladdin)类型的值，就可以接受几种响应啦)
> >
> > **cookie**：缓存信息。
> >
> > **Cache-Control**：对缓存进行控制。比如你希望禁止缓存，或者缓存一年，或者一月，这些都是通过设置这个属性。
>
>  
>
>  
>
> ### **HTTP响应报文也由三部分组成**
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170707145557633.jfif)
>
> **响应行（12） 组成：1是报文协议及版本，2是状态码及描述。**
>
> **响应头（3）：和请求头一样，由属性组成。**
>
> **响应体（4）：是服务器返回给客户端的文本信息。**
>
>  
>
> > **HTTP响应报文属性**
> >
> > **Cache-Control** ：响应输出到客户端后，服务端通过该报文头属告诉客户端如何控制响应内容的缓存。常见的有：（默认      为private）
> >
> > ​        private:             客户端可以缓存
> >         public:              客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的）
> >         max-age=xxx:   缓存的内容将在 xxx 秒后失效
> >         no-cache:          需要使用对比缓存来验证缓存数据
> >         no-store:           所有内容都不会缓存
> >
> > **Location：**当我们想要页面重定向**redirect**的时候，设置Location的属性值（地址）跳转到该地址
> >
> > **Cookie：缓存信息**
>
>  
>
>  
>
> > 
> >
> > 响应状态码
> >
> > 
> >
> > - 1xx 消息，一般是告诉客户端，请求已经收到了，正在处理，别急...
> > - 2xx 处理成功，一般表示：请求收悉、我明白你要的、请求已受理、已经处理完成等信息.
> > - 3xx 重定向到其它地方。它让客户端再发起一个请求以完成整个处理。
> > - 4xx 处理发生错误，责任在客户端，如客户端的请求一个不存在的资源，客户端未被授权，禁止访问等。
> > - 5xx 处理发生错误，责任在服务端，如服务端抛出异常，路由出错，HTTP版本不支持等。
> >
> > ◆200 (OK): 找到了该资源，并且一切正常。
> >
> > ◆302/307：临时重定向，指出请求的文档已被临时移动到别处, 此文档的新的url在location响应头中给出
> >
> > ◆304 (NOT MODIFIED): 该资源在上次请求之后没有任何修改。这通常用于浏览器的缓存机制。
> >
> > ◆401 (UNAUTHORIZED): 客户端无权访问该资源。这通常会使得浏览器要求用户输入用户名和密码，以登录到服务器。
> >
> > ◆403 (FORBIDDEN): 客户端未能获得授权。这通常是在401之后输入了不正确的用户名或密码。
> >
> > ◆404 (NOT FOUND): 在指定的位置不存在所申请的资源。
> >
> > ◆500 Internal Server Error：看到这个错误，你就应该查查服务端的日志了，肯定抛出了一堆异常，别睡了，起来改BUG去吧！
>
>  

 

#### **DNS协议工作流程**

**1）通过域名访问网页**

**2）计算机会先将域名发送到一个解析域名的服务器上**

- ​     在其服务器上有很多服务器，能解析各种各样的域名，比如有专门解析.org的，解析.com的，解析.net的。等等，最主要的有一个根域名服务器
- ​     域名解析(在服务器上查找IP地址)的过程有两种算法，迭代查询，递归查询。一般是两种查询的结合
- ​    本机计算机找到其中一台解析域名的服务器(可能是.com)，如果没有找到对应的IP地址，那么就会去找根域名服务器，根域名服务器知道所有的子服务器，所以他肯定知道该域名所对应的IP地址在那个子服务器中，所以告诉第一次查询的服务器要他去另一台服务器上找，找到了，就将其返回给计算机，以后在有另一台计算机也通过这个域名访问，那么第一台服务器会有原来的域名IP地址的缓存，就不用去找根服务器了。

**3）找到服务器ip地址就可以访问了** 

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215144658907.png)



### 2.传输层

**http封装请求数据包以后传给传输层，tcp协议部分开始运作。这里将数据包和TCP报头生成TCP报文，打包成新的数据包。**

**TCP报文结构（点击查看详情）：**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215145716455.png)

> **为了完成三次挥手四次握手，这里需要知道序列号seq、确认应答序号ack（小写字母）、控制位：**
>
>  
>
> **序列号seq：**
>
> 　　　　因为在TCP是面向字节流的，他会将报文都分成一个个字节，给每个字节进行序号编写，比如一个报文有900个字节组成，那么就会编成1-900个序号，然后分几部分来进行传输，
>
> 　　　　比如第一次传，序列号就是1，传了50个字节， 那么第二次传，序列号就为51，所以序列号就是传输的数据的第一个字节相对所有的字节的位置。
>
> **确认应答ack：**
>
> 　　　　如刚说的例子，第一次传了50个字节给对方，对方也会回应你，其中带有确认应答，就是告诉你下一次要传第51个字节来了，所以这个确认应答就是告诉对方下一次要传第多少个字节了。也就是说告诉序列号下一次从哪里开始
>
> **控制位目前有6个**
>
> 　　　　URG:紧急，当URG为1时，表名紧急指针字段有效，标识该报文是一个紧急报文，传送到目标主机后，不用排队，应该让该报文尽量往下排，让其早点让应用程序给接受。
>
> 　　　　ACK:确认，当ACK为1时，确认序号才有效。当ACK为0时，　　　　确认序号没用
>
> 　　　　PSH：推送，当为1时，当遇到此报文时，会减少数据向上交付，本来想应用进程交付数据是要等到一定的缓存大小才发送的，但是遇到它，就不用在等足够多的数据才向上交付，
>
> 　　　　　　　　而是让应用进程早点拿到此报文，这个要和紧急分清楚，紧急是插队，但是提交缓存大小的数据不变，这个推送就要排队，但是遇到他的时候，会减少交付的缓存数据，提前交付。
>
> 　　　　RST:复位，报文遇到很严重的差错时，比如TCP连接出错等，会将RST置为1，然后释放连接，全部重新来过。
>
> 　　　　SYN：同步，在进行连接的时候，也就是三次握手时用得到，下面会具体讲到，配合ACK一起使用
>
> 　　　　FIN：终止，在释放连接时，也就是四次挥手时用的。

#### **三次握手：**

**在通信之前，会先通过三次握手的机制来确认两端口之间的连接是否可用。而UDP是不需要确认的，直接传**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170605110405666.png)![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215155632492.png)

> **最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。**
>
> **某个时刻客户端和服务器要进行通信，此时双方都有备好的端口，服务器的端口会处于监听状态，等待客户端的连接。**

**怎么知道服务器端口号的？**

​    http在访问url中已经拿到！

**怎么知道客户端要连接进来，服务器才进入listen状态？**

​    TCP老早就创建了传输控制块TCB，时刻待命准备接受客户端的连接请求，此时服务器就被动地进入了listen状态。

 

**第一次握手：**

客户端想要连接，创建传输控制块TCB，状态变为主动打开。发送给服务器不包含数据内容的连接请求报文。该请求报文首部中同步位SYN=1，同时选择一个初始序列号seq=x（携带了x个字节）。然后客户端进入 SYN-SENT （同步已发送）状态，告诉服务器我想和你同步连接。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。

**第二次握手：**

TCP服务器收到连接请求报文，如果同意连接则发送确认报文。为了保证下次客户端发送报文时seq序列号是正确的，需要发送确认号ack=x+1，同时确认号ack要生效必须发送ACK=1，再加上同步位SYN=1，序列号seq=y（携带Y个字节），然后服务器也进 入SYN-RCVD (同步已收到) 状态，完成同步连接。这个报文也是SYN报文，也不能携带数据，但是同样要消耗一个序号。 

**第三次握手：**

 客户端收到确认后还要再向服务器发送确认报文。确认报文已经不是请求报文SYN了，不再包含SYN同步位。发送的内容有序列号seq=x+1（和第二次握手的ACK对应），确认号ack=y+1，ACK=1。客户端发送确认报文以后进入ESTABLISHED（已建立）状态，服务器接收到确认报文以后也进入ESTABLISHED状态。此时TCP连接完成建立。

**然后就可以发送TCP接收到Http的数据包后生成的新数据包了！**

 

> **但是貌似看起来两次握手请求就可以完成事，为什么非要三次握手呢？**
>
> 主要是为了防止已经失效的连接请求报文突然又传到了服务器，从而产生错误。
>
> 如果是两次握手，假设一种情景：客户端发送了第一个请求连接报文并未丢失，只是因为网络问题在网络节点中滞留太久了。由于客户端迟迟没有收到确认报文，以为服务器没有收到。于是再发送一条请求连接报文，此时一路畅通完成两次握手建立连接，传输数据，关闭连接。然后那个前一条龟速的请求报文终于走到了服务器，再次和服务器建立连接，这就造成了不必要的资源浪费。
>
> 如果是三次握手，就算那一条龟速的请求报文最后到达了服务器，然后服务器也发送了确认连接报文，但是此时客户端已经不会再发出确认报文了，服务器也接受不到确认报文，于是无法建立连接。

#### 四次挥手：

**数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170606084851272.png)

**第一次挥手：**

客户端从ESTABLISHED状态变为主动关闭状态，客户端发送请求释放连接报文给服务器，FIN=1，seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

**第二次挥手：**

服务器接收到客户端发来的请求释放报文以后，发送确认报文告诉客户端我收到了你的请求，内容差不多就是seq=v，ack=u+1，ACK=1，此时服务器进入CLOSE-WAIT（关闭等待）状态。

为什么是CLOSE-WAIT状态？可能自己服务器这端还有数据没有发送完，所以这个时候整个TCP的连接就变成了半关闭状态。服务器还能发送数据，客户端也能接收数据，但客户端不能再发送数据了，只能发送确认报文。

客户端接收到服务器传来的确认报文以后，进入 FIN-WAIT-1（终止等待2）状态，等待服务器发送连接释放的报文（在这之前，还需要接受服务器没有发送完的最后的数据）。 

**第三次挥手：**

服务器所有的数据都发送完了，认为可以关闭连接了，于是向客户端发送连接释放报文，内容FIN=1，seq=w，ack=u+1（客户端没发送消息，所以提醒客户端下一次还是从u+1开始发送序列），ACK=1。此时服务器进入了 LAST-ACK（最后确认）状态，等待客户端发送确认报文。

**第四次挥手：**

客户端接收到了服务器发送的连接释放报文，必须发出确认。确认报文seq=u+1，ack=w+1，ACK=1。此时客户端进入 TIME-WAIT （时间等待）状态，但是没有立马关闭。此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

因为这个确认报文可能丢失。服务器收不到确认报文心想这可能是我没传到或者丢失了啊，于是服务器再传一个FIN，然后客户端再重新发送一个确认报文。然后刷新2∗∗MSL时间。直到这个时间内收不到FIN连接释放报文，客户端撤销TCB进入CLOSE状态。

而服务器，在接收到确认报文的时候就立马变为CLOSE状态了。所以服务器结束TCP连接的时间略早于客户端。

 

> **万一确认连接以后客户端故障怎么办？**
>
> TCP设有一个保活计时器。显然客户端故障时服务器不会智障般等下去，白白浪费资源。服务器每次收到一次客户端的请求以后都会刷新这个保活计时器，时间通常设置为2小时。若2个小时依旧没有收到客户端的任何数据，服务器会发送一个探测报文段，每隔75分钟发一个，如果连发十个都没有数据反应，那么服务器就知道客户端故障了，关闭连接。

 

### 3.网络层

**TCP数据包到了这一层，再加上IP报文生成新的IP数据包**

**前面有提到网络层主要负责物理地址（mac）和逻辑地址（ip）的转换。** 

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215191530461.png)

**ICMP（Internet Control Message Protocol：互联网控制消息协议）：主要负责网络层和传输层的数据交换，是为了更有效地转发IP数据报文和提高数据报文交付成功的机会，是介于传输层和网络层之间的协议。**

**ARP（Address Resolution Protocol：地址解析协议）：主要是将IP地址解析成MAC地址的协议。**

**RARP（Reverse Address Resolution Protocol：逆地址解析协议）****：正好相反，是将MAC地址解析成IP地址的协议。**

**IP协议（Internet Protocol：网际协议）：是TCP/IP协议族中最为核心的协议。它提供不可靠、无连接的服务，也即依赖其他层的协议进行差错控制。**

**报文结构格式（了解更多）：**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215194736827.png)

> **3.IP协议**
>
> IP协议提供非可靠，无连接的数据报传输服务。
>
> **非可靠**：这意味着它并不保证所要传输的数据一定会到达目的地。（当路由出错导致某个数据传输失败时，会丢掉此数据并发回一个ICMP信息回去。可靠性需要由更上层的协议提供，如TCP协议）。
>
> **无连接**：这代表 IP datagram（数据报）在传输中没有连接起来，他们是一块一块各自分开的，分开独立处理。（比如需要向某个地方发送两个数据报A、B，他们两个有可能会经由不同的路径去到达目的地，有可能B要比A先到达）。
>
> **数据报字段如图**
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20181210101030667.png)
>
> 4-bit version：是IP协议的版本，当前版本是4。
>
> 4-bit header length：代表IP header的长度。
>
> 8-bit type of service（TOS）：服务类型，包括：最小延时，最大传输，最大可靠性，最小消耗等。
>
> 16-bit total length（in bytes）：整个IP数据报的字节数。
>
> 16-bit identification：识别号，主机每发送一次都会自动增加。
>
> 3-bit flags：标记位，用于标记是否被分段。
>
> 13-bit fragment offset ：分段号。
>
> 8-bit time for live（TTL）：生存时间。
>
> 8-bit protocol：代表此IP数据所运输的是来自哪个上层协议的数据，如TCP、UDP等。
>
> 16-bit header checksum：用于校验header数据。
>
> 32-bit source IP address：源IP地址。
>
> 32-bit detination IP address：目标IP地址

#### **IP地址 ：**

**TCP/IP协议网络上每个网络适配器都有一个唯一的ip地址**

**IP 地址是一个 32 位的地址,这个地址通常分成 4 端，每 8 个二进制为一段，但是为了方便阅读，通常会将每段都转换为十进制来显示，比如大家非常熟悉的 192.168.0.1（本地局域网）**

**IP地址分为两部分，一部分是网络ID，另一部分是主机ID。但是具体哪一部分是网络D，哪一部分是主机ID并没有明确规定。因为有的网络需要主机很少，因此较短；而有些比较长，因此主机ID较长。**

**绝大部分 IP 地址属于以下几类**

​        **A 类地址：IP 地址的前 8   位代表网络 ID ，后 24 位代表主机 ＩＤ        B 类地址：IP 地址的前 16 位代表网络 ID ，后 16 位代表主机 ＩＤ        C 类地址：IP 地址的前 24 位代表网络 ID ，后 8   位代表主机 ＩＤ从以下的图中就可以很简单区分IP地址属于哪一类了，比如我的ip地址192.168.0.1就是属于C类**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170404105414667.png)

**注意：        1.十进制第一段大于 223 的属于 D 类和 E 类地址，这两类比较特殊也不常见，这里就不做详解介绍了。        2.每一类都有一些排除地址，这些地址并不属于该类，他们是在一些特殊情况使用地址        3.除了这样的方式来划分网络，我们还可以把每个网络划分为更小的网络块，称之为子网**

 

### **4.网络接口层（更多）**

**其实这里还可以分为数据链路层和物理层**

**这一层主要涉及到一些物理传输，比如以太网，无线局域网，电缆等**

**IP数据包到了这层就不一样了啊！数据链路会在IP数据报的首尾加上首部和尾部代表数据包的结束，封装成帧。首部和尾部都是8位2进制表示，可以一样也可以不一样。**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\2019021520132349.png)



![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215203852148.png)

　　**链路：一条点到点的物理线路段，中间没有任何其他的交换结点，通俗的将，就是一根线，其中不经过任何东西，这样的就是链路，一条链路只是一条通路的一个组成部分**

　　**数据链路：除了物理线路外，还必须有通信协议来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。 通俗讲，就是经过了一些交换机呀，什么的。**

　　　　　　　**最终到达目的地，所有路段就是数据链路，而数据链路中就包含了多段链路。**

　　**适配器：也就是网卡，就是用来实现数据链路上一些协议。**

​       **帧：数据链路层上传送的就是帧**

如果再往下到物理层呢？就成为比特流传输了。

 

 

 

至此，一个请求就完成了由应用层到物理层的传递。在各种交换机中找到最后的服务器地址。然后再把数据封装反着来一遍。再将请求一步步封装传出去，同样的方式由客户端拿到数据，Http协议解析读取显示。

## 二 TCP 三次握手和四次挥手(面试常客)

为了准确无误地把数据送达目标处，TCP协议采用了三次握手策略。

### 2.1 TCP 三次握手漫画图解

如下图所示，下面的两个机器人通过3次握手确定了对方能正确接收和发送消息(图片来源：《图解HTTP》)。
![TCP三次握手](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/三次握手.png)

**简单示意图：**
![TCP三次握手](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/三次握手2.png)

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

### 2.2 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

### 2.3 第2次握手传回了ACK，为什么还要传回SYN？

接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信。”

> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。

### 2.5 为什么要四次挥手

![TCP四次挥手](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/TCP四次挥手.png)

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个FIN给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

上面讲的比较概括，推荐一篇讲的比较细致的文章：[https://blog.csdn.net/qzcsu/article/details/72861891](https://blog.csdn.net/qzcsu/article/details/72861891)

## 三 TCP,UDP 协议的区别

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

### 相同点

UDP协议和TCP协议都是传输层协议。

TCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个TCP连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。

UDP（User Data Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给IP层的数据报发送出去，但是不能保证它们能到达目的地。由于UDP在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。

### 不同点

- 报头不同
- 特点不同
- 协议不同

### UDP

- 报头
  ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20180901091529706.png)

**UDP数据报最大长度64K（包含UDP首部），如果数据长度超过64K就需要在应用层手动分包，UDP无法保证包序，需要在应用层进行编号。**

- 特点

  1. **无连接：**知道对端的IP和端口号就直接进行传输, 不需要建立连接。
  2. **不可靠：**没有确认机制, 没有重传机制; 如果因为网络故障该段无法发到对方, UDP协议层也不会给应用层返回任何错误信息。
  3. **面向数据报：**不能够灵活的控制读写数据的次数和数量，应用层交给UDP多长的报文, UDP原样发送, 既不会拆分, 也不会合并。
  4. 数据收不够灵活，但是能够明确区分两个数据包，**避免粘包**问题。

- 协议：

  NFS: 网络文件系统
  TFTP: 简单文件传输协议
  DHCP: 动态主机配置协议
  BOOTP: 启动协议(用于无盘设备启动)
  DNS: 域名解析协议

### TCP

- 报头
  ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20180901092556271.png)

```
源/目的端口号: 表示数据是从哪个进程来, 到哪个进程去;
32位序号/32位确认号: 不一定从0开始（作用：保证确认应答；保证数据按序到达；去重）
4位TCP报头长度: 表示该TCP头部有多少个32位bit(有多少个4字节); 所以TCP报头最大长度是15 * 4 = 60 字节
6位标志位:
    1. URG: 紧急指针是否有效
    2. ACK: 确认号是否有效
    3. PSH: 提示接收端应用程序立刻从TCP缓冲区把数据读走
    4. RST: 对方要求重新建立连接; 我们把携带RST标识的称为复位报文段
    5. SYN: 请求建立连接; 我们把携带SYN标识的称为同步报文段
    6. FIN: 通知对方, 本端要关闭了, 我们称携带FIN标识的为结束报文段
16位窗口大小: 接收缓冲区剩余的空间大小 
16位校验和: 发送端填充, CRC校验. 接收端校验不通过, 则认为数据有问题. 此处的检验和不光包含TCP 首部, 也包含TCP数据部分. 
16位紧急指针: 标识哪部分数据是紧急数据; 12345678910111213
```

- 特点
  - **面向连接**
  - 可靠传输(见第四点)

**面向字节流：**

创建一个TCP的socket, 同时在内核中创建一个发送缓冲区和一个接收缓冲区；
另一方面, TCP的一个连接, 既有发送缓冲区, 也有接收缓冲区, 那么对于这一个连接, 既可以读数据, 也可以写数据. 这个概念叫做 全双工 。

1. 调用write时, 数据会先写入发送缓冲区中;
2. 如果发送的字节数太长, 会被拆分成多个TCP的数据包发出; 如果发送的字节数太短, 就会先在缓冲区里等待, 等到缓冲区长度差不多了, 或者其他合适的时机发送出去;
3. 接收数据的时候, 数据也是从网卡驱动程序到达内核的接收缓冲区;
4. 然后应用程序可以调用read从接收缓冲区拿数据;

**TCP粘包问题**

1. 首先要明确, 粘包问题中的 “包” , 是指的应用层的数据包；
2. 在TCP的协议头中, 没有如同UDP一样的 “报文长度” 这样的字段, 但是有一个序号这样的字段；
3. 站在传输层的角度, TCP是一个一个报文过来的，按照序号排好序放在缓冲区中；
4. 站在应用层的角度, 看到的只是一串连续的字节数据. 那么应用程序看到了这么一连串的字节数据, 就不知道从哪个部分开始到哪个部分是一个完整的应用层数据包。

**那么如何避免粘包问题呢?**
**归根结底就是一句话, 明确两个包之间的边界.**

1.对于定长的包, 保证每次都按固定大小读取即可;
2.对于变长的包, 可以在报头的位置, 约定一个包总长度的字段, 从而就知道了包的结束位置;
3.对于变长的包, 还可以在包和包之间使用明确的分隔符。
4.TLV格式的数据传输

- TCP异常情况
  1. 进程终止: 进程终止会释放文件描述符, 仍然可以发送FIN. 和正常关闭没有什么区别.
  2. 机器重启: 和进程终止的情况相同
  3. 机器掉电/网线断开: 接收端认为连接还在, 一旦接收端有写入操作, 接收端发现连接已经不在了, 就会进行 reset. 即使没有写入操作, TCP自己也内置了一个保活定时器, 会定期询问对方方是否还在. 如果对方不在, 也会把连接释放
- **协议**

HTTP
HTTPS
SSH
Telnet
FTP
SMTP





## 四 TCP 协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。 
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
4. TCP 的接收端会丢弃重复的数据。 
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 

### 4.1 ARQ协议

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。

#### 停止等待ARQ协议

- 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

**优点：** 简单

**缺点：** 信道利用率低，等待时间长

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。

#### 连续ARQ协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。

**缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

### 4.2 滑动窗口和流量控制

> ## 概述
>
> 滑动窗口实现了TCP流控制。首先明确**滑动窗口**的范畴：TCP是双工的协议，会话的双方都可以同时接收和发送数据。TCP会话的双方都各自维护一个`发送窗口`和一个`接收窗口`。各自的`接收窗口`大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的`发送窗口`则要求取决于对端通告的`接收窗口`，要求相同。
>
> 滑动窗口解决的是**流量控制**的的问题，就是如果接收端和发送端对数据包的处理速度不同，如何让双方达成一致。接收端的缓存传输数据给应用层，但这个过程不一定是即时的，如果发送速度太快，会出现接收端数据overflow，流量控制解决的是这个问题。
>
> ## 窗口的概念
>
> 发送方的发送缓存内的数据都可以被分为4类:
> \1. 已发送，已收到ACK
> \2. 已发送，未收到ACK
> \3. 未发送，但允许发送
> \4. 未发送，但不允许发送
>
> 其中类型2和3都属于发送窗口。
>
> 接收方的缓存数据分为3类：
> \1. 已接收
> \2. 未接收但准备接收
> \3. 未接收而且不准备接收
>
> 其中类型2属于接收窗口。
>
> 窗口大小代表了设备一次能从对端处理多少数据，之后再传给应用层。缓存传给应用层的数据不能是乱序的，窗口机制保证了这一点。现实中，应用层可能无法立刻从缓存中读取数据。
>
> ## 滑动机制
>
> 1. 发送窗口只有收到发送窗口内字节的ACK确认，才会移动发送窗口的左边界。
> 2. 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。
> 3. 遵循快速重传、累计确认、选择确认等规则。
> 4. 发送方发的window size = 8192;就是接收端最多发送8192字节，这个8192一般就是发送方接收缓存的大小。
>
> ## 模拟动画
>
> ### 模拟特点
>
> 找到了一个模拟TCP窗口发送的[动画的地址](http://www.exa.unicen.edu.ar/catedras/comdat1/material/Filminas3_Practico3.swf)，稍微有缺陷：1. 丢包率如果设得太高，有时无论重发多少次都不能恢复正常 2. 窗口最大可为10，其实应该为9
>
> 明确发送端和接收端，发送A~S数据包，我们不会从头到尾分析，因为过程比较长。
> \1. 简化了窗口大小，双方窗口大小都一直是4
> \2. 设置一定的丢包率，否则没什么值得分析的，包括sender发送的数据包和receiver回复的ACK包。
> \3. 简化重传机制，出现丢包则直接重传，不等3个冗余ACK和超时。
> \4. 既不是选择重传也不是退回N步，重传的包是随机的
> 发
>
> ### 分析滑动窗口机制
>
> 1. 首先发送端发送A,B,C,D四个包，但是A,B丢失，只有C,D到达接收端。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\42138740462_ed4ce64c1b_b-1600147916917.jpg)
> 2. 接收端没有收到A，所以不回复ACK包。发送端重传A,B,C,D四个包，这次全都到达了。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\42138740402_dbbbf52c8c_b-1600147916277.jpg)
> 3. 接收端先获得A，发ACK包A，但是中途丢失；获得B后，根据累计确认的原则，发D的ACK包，然后窗口滑动。再次获得C,D后，连续回复2个D的ACK包，其中C对应的ACK包丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728687_a5673da755_b-1600147916965.jpg)
> 4. 发送端连收2个D的ACK包，说明4个包对方都已收到，窗口滑动，发E,F,G,H包，其中G包丢失。现在整个序列的状态：ABCD是已发送已确认，EFGH是已发送未确认，I~S是不能发送。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728577_04e0867716_b-1600147917029.jpg)
> 5. 接收端先收到E，发ACK包；收到F后发F的ACK包；未收到G，还是发F的ACK包；收到H，还是发F的ACK包。不幸的是，三个ACK包全都丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728427_a5b7d4b107_b-1600147916757.jpg)
> 6. 发送端收到E的ACK包，窗口向右滑动一位；然后再发送F,G,H,I，其中F丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728297_65698014e9_b-1600147916813.jpg)
> 7. 接收端获得I，因为没有G，只好回复F的ACK包。相继收到G,H包。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\28312507728_96c5813bee_b-1600147917133.jpg)
> 8. 接收端根据累计确认，连发两个I包，其中H对应的丢失。窗口向右滑动。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\41284211495_31f906941b_b-1600147917165.jpg)
> 9. 发送端接收I的ACK包后，向右滑动四位。发送J,K,L,M四个包，后面不再分析。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728077_b406cc3293_b-1600147917073.jpg)
>
> 从上面的过程中，我们可以得到以下结论：
> \1. TCP连接是通过数据包和ACK实现的，我们作为第三者可以看到双方发包的过程，但接受者在收到之前不知道发送方发的是什么，同样的，发送方在收到ACK前也不知道对方是否成功接收。
>
> 1. 发送方没有收到接收方发回的ACK，就不能向右滑动。假设发送方向接收方发了ABCD就滑动，只要对方没收到A，就不能滑动，那么就会出现二者不同步的局面。
> 2. 滑动窗口提高了信道利用率，TCP是发送报文段为单位的，假如每发一个报文就要等ACK，那么对于大数据包，等待时间就太长了。只要发送的报文在滑动窗口里面，不用等每个ACK回来就可以向右滑动。本例中，开始接收端空着AB，只有CD，此时不能滑动；之后接收到EF和H，直接向右滑动2位，不必等G到位。
> 3. 窗口大小不能大于序号空间大小的一半。目的是为了不让两个窗口出现交迭，比如总大小为7，窗口大小都为4，接收窗口应当滑动4，但只剩3个序号，导致两个窗口交迭。
> 4. 有一种情况没出现：发送方发ABCD，接收方都收到然后向右滑动，但回复的ACK包全丢了。发送方未收到任何ACK， timeout后会重发ABCD，此时的接收方按累计确认的原则，收到ABCD后只会重发D的ACK，发送方收到后向右滑动。
>
> ## 对比滑动窗口和拥塞窗口
>
> 滑动窗口是控制接收以及同步数据范围的，通知发送端目前接收的数据范围，用于流量控制，接收端使用。拥塞窗口是控制发送速率的，避免发的过多，发送端使用。因为tcp是全双工，所以两边都有滑动窗口。
> 两个窗口的维护是独立的，滑动窗口主要由接收方反馈缓存情况来维护，拥塞窗口主要由发送方的拥塞控制算法检测出的网络拥塞程度来决定的。
>
> 拥塞窗口控制sender向connection传输数据的速率，使这个速率为网络拥堵状况的函数。

### 4.3 拥塞控制

> 在某段时间，若**对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏**，这种情况就叫做**网络拥塞**。
>
> 在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。
>
> 若**出现拥塞而不进行控制**，整个网络的**吞吐量将随输入负荷的增大而下降**。
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731190238241-1600147962824.png)
> 当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。
> **TCP的四种拥塞控制算法**
> 1.慢开始
> 2.拥塞控制
> 3.快重传
> 4.快恢复
> **假定**：
> 1.数据是单方向传送，而另一个方向只传送确认
> 2.接收方总是有足够大的缓存空间，因而发送发发送窗口的大小由网络的拥塞程度来决定
> 3.以TCP报文段的个数为讨论问题的单位，而不是以字节为单位
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731155254165-1600147963079.png)
> **示例如下：**
> 传输轮次：发送方给接收方发送数据报文段后，接收方给发送方发回相应的确认报文段，一个传输轮次所经历的时间就是往返时间RTT(RTT并非是恒定的数值），使用传输轮次是为了强调，把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个报文段的确认，拥塞窗口cwnd会随着网络拥塞程度以及所使用的拥塞控制算法动态变化。
>
> 在tcp双方建立逻辑链接关系时， 拥塞窗口cwnd的值被设置为1，还需设置慢开始门限ssthresh,在执行慢开始算法时，发送方每收到一个对新报文段的确认时，就把拥塞窗口cwnd的值加一，然后开始下一轮的传输，当拥塞窗口cwnd增长到慢开始门限值时，就使用拥塞避免算法。
>
> **慢开始：**
> 假设当前发送方拥塞窗口cwnd的值为1，而发送窗口swnd等于拥塞窗口cwnd，因此发送方当前只能发送一个数据报文段（拥塞窗口cwnd的值是几，就能发送几个数据报文段），接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为2，
>
> > 发送方此时可以连续发送两个数据报文段，接收方收到该数据报文段后，给发送方一次发回2个确认报文段，发送方收到这两个确认报文后，将拥塞窗口的值加2变为4，发送方此时可连续发送4个报文段，接收方收到4个报文段后，给发送方依次回复4个确认报文，发送方收到确认报文后，将拥塞窗口加4，置为8，发送方此时可以连续发送8个数据报文段，接收方收到该8个数据报文段后，给发送方一次发回8个确认报文段，发送方收到这8个确认报文后，将拥塞窗口的值加8变为16，
>
> 当前的拥塞窗口cwnd的值已经等于慢开始门限值，之后改用拥塞避免算法。
>
> **拥塞避免：**
> 也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长。同理，16+1……直至到达24，假设24个报文段在传输过程中丢失4个，接收方只收到20个报文段，给发送方依次回复20个确认报文段，一段时间后，丢失的4个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改cwnd和ssthresh.并重新开始慢开始算法，如图所示：
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731165743903-1600147962820.png)![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731165605396-1600147963079.png)
> **快速重传：**
> 发送方发送1号数据报文段，接收方收到1号报文段后给发送方发回对1号报文段的确认，在1号报文段到达发送方之前，发送方还可以将发送窗口内的2号数据报文段发送出去，接收方收到2号报文段后给发送方发回对2号报文段的确认，在2号报文段到达发送方之前，发送方还可以将发送窗口内的3号数据报文段发送出去，
>
> > 假设该报文丢失，发送方便不会发送针对该报文的确认报文给发送方，发送方还可以将发送窗口内的4号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，发送方还可以将发送窗口中的5号报文段发送出去,接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段,，发送方还可以将发送窗口内的最后一个数据段即6号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，
>
> 此时，发送方收到了累计3个连续的针对2号报文段的重复确认，立即重传3号报文段，接收方收到后，给发送方发回针对6号报文的确认，表明，序号到6为至的报文都收到了，这样就不会造成发送方对3号报文的超时重传，而是提早收到了重传。
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184314574-1600147962875.png)
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184640178-1600147963079.png)![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184935595-1600147963079.png)

## 四 tcp粘包问题和解决方案

> 在进行Java NIO学习时，发现，如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这就是TCP协议中经常会遇到的粘包以及拆包的问题。
>
> 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。
>
> ### 粘包、拆包表现形式
>
> 现在假设客户端向服务端连续发送了两个数据包，用packet1和packet2来表示，那么服务端收到的数据可以分为三种，现列举如下：
>
> 第一种情况，接收端正常收到两个数据包，即没有发生拆包和粘包的现象，此种情况不在本文的讨论范围内。![normal](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144359680)
>
> 第二种情况，接收端只收到一个数据包，由于TCP是不会出现丢包的，所以这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理。![one](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144417818)
>
> 第三种情况，这种情况有两种表现形式，如下图。接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。这两种情况如果不加特殊处理，对于接收端同样是不好处理的。![half_one](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144437428)![one_half](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144453881)
>
> ### 粘包、拆包发生原因
>
> 发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，
>
> 1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
>
> 2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
>
> 3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
>
> 4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。
>
> 等等。
>
> ### 粘包、拆包解决办法
>
> 通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：
>
> 1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
>
> 2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
>
> 3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。
>
> 等等。
>
> ### 样例程序
>
> 我将在程序中使用两种方法来解决粘包和拆包问题，固定数据包长度和添加长度首部，这两种方法各有优劣。固定数据包长度传输效率一般，尤其是在要发送的数据长度长短差别很大的时候效率会比较低，但是编程实现比较简单；添加长度首部虽然可以获得较高的传输效率，冗余信息少且固定，但是编程实现较为复杂。下面给出的样例程序是基于之前的文章《[Java中BIO，NIO和AIO使用样例](http://blog.insanecoder.top/javazhong-bio-niohe-aioshi-yong-yang-li/)》中提到的NIO实例的，如果对NIO的使用还不是很熟悉，可以先了解一下Java中NIO编程。
>
> #### 固定数据包长度
>
> 这种处理方式的思路很简单，发送端在发送实际数据前先把数据封装为固定长度，然后在发送出去，接收端接收到数据后按照这个固定长度进行拆分即可。发送端程序如下：
>
> ```
> // 发送端
> String msg = "hello world " + number++;  
> socketChannel.write(ByteBuffer.wrap(new FixLengthWrapper(msg).getBytes()));
>  
> // 封装固定长度的工具类
> public class FixLengthWrapper {
>  
>     public static final int MAX_LENGTH = 32;
>     private byte[] data;
>  
>     public FixLengthWrapper(String msg) {
>         ByteBuffer byteBuffer = ByteBuffer.allocate(MAX_LENGTH);
>         byteBuffer.put(msg.getBytes());
>         byte[] fillData = new byte[MAX_LENGTH - msg.length()];
>         byteBuffer.put(fillData);
>         data = byteBuffer.array();
>     }
>  
>     public FixLengthWrapper(byte[] msg) {
>         ByteBuffer byteBuffer = ByteBuffer.allocate(MAX_LENGTH);
>         byteBuffer.put(msg);
>         byte[] fillData = new byte[MAX_LENGTH - msg.length];
>         byteBuffer.put(fillData);
>         data = byteBuffer.array();
>     }
>  
>     public byte[] getBytes() {
>         return data;
>     }
>  
>     public String toString() {
>         StringBuilder sb = new StringBuilder();
>         for (byte b : getBytes()) {
>             sb.append(String.format("0x%02X ", b));
>         }
>         return sb.toString();
>     }
> }
> ```
>
> 可以看到客户端在发送数据前首先把数据封装为长度为32bytes的数据包，这个长度是根据目前实际数据包长度来规定的，这个长度必须要大于所有可能出现的数据包的长度，这样才不会出现把数据“截断”的情况。接收端程序如下：
>
> ```
> \private static void processByFixLength(SocketChannel socketChannel) throws IOException {  
>     while (socketChannel.read(byteBuffer) > 0) {
>  
>         byteBuffer.flip();
>         while (byteBuffer.remaining() >= FixLengthWrapper.MAX_LENGTH) {
>             byte[] data = new byte[FixLengthWrapper.MAX_LENGTH];
>             byteBuffer.get(data, 0, FixLengthWrapper.MAX_LENGTH);
>             System.out.println(new String(data) + " <---> " + number++);
>         }
>         byteBuffer.compact();
>     }
> }
> ```
>
> 可以看出接收端的处理很简单，只需要每次读取固定的长度即可区分出来不同的数据包。
>
> #### 添加长度首部
>
> 这种方式的处理较上面提到的方式稍微复杂一点。在发送端需要给待发送的数据添加固定的首部，然后再发送出去，然后在接收端需要根据这个首部的长度信息进行数据包的组合或拆分，发送端程序如下：
>
> ```
> // 发送端
> String msg = "hello world " + number++;  
> // add the head represent the data length
> socketChannel.write(ByteBuffer.wrap(new PacketWrapper(msg).getBytes()));
>  
> // 添加长度首部的工具类
> public class PacketWrapper {
>  
>     private int length;
>     private byte[] payload;
>  
>     public PacketWrapper(String payload) {
>         this.payload = payload.getBytes();
>         this.length = this.payload.length;
>     }
>  
>     public PacketWrapper(byte[] payload) {
>         this.payload = payload;
>         this.length = this.payload.length;
>     }
>  
>     public byte[] getBytes() {
>         ByteBuffer byteBuffer = ByteBuffer.allocate(this.length + 4);
>         byteBuffer.putInt(this.length);
>         byteBuffer.put(payload);
>         return byteBuffer.array();
>     }
>  
>     public String toString() {
>         StringBuilder sb = new StringBuilder();
>         for (byte b : getBytes()) {
>             sb.append(String.format("0x%02X ", b));
>         }
>         return sb.toString();
>     }
> }
> ```
>
> 从程序可以看到，发送端在发送数据前首先给待发送数据添加了代表长度的首部，首部长为4bytes（即int型长度），这样接收端在收到这个数据之后，首先需要读取首部，拿到实际数据长度，然后再继续读取实际长度的数据，即实现了组包和拆包的操作。程序如下：
>
> ```
> private static void processByHead(SocketChannel socketChannel) throws IOException {
>  
>     while (socketChannel.read(byteBuffer) > 0) {
>         // 保存bytebuffer状态
>         int position = byteBuffer.position();
>         int limit = byteBuffer.limit();
>         byteBuffer.flip();
>         // 判断数据长度是否够首部长度
>         if (byteBuffer.remaining() < 4) {
>             byteBuffer.position(position);
>             byteBuffer.limit(limit);
>             continue;
>         }
>         // 判断bytebuffer中剩余数据是否足够一个包
>         int length = byteBuffer.getInt();
>         if (byteBuffer.remaining() < length) {
>             byteBuffer.position(position);
>             byteBuffer.limit(limit);
>             continue;
>         }
>         // 拿到实际数据包
>         byte[] data = new byte[length];
>  
>         byteBuffer.get(data, 0, length);
>         System.out.println(new String(data) + " <---> " + number++);
>         byteBuffer.compact();
>     }
> }
> ```
>
> 关键信息已经在程序中做了注释，可以很明显的感觉到这种方法的处理难度相对于固定长度要大一些，不过这种方式可以获取更大的传输效率。
>
> 这里需要提醒各位同学一个问题，由于我在测试的时候采用的是一台机器连续发送数据来模拟高并发的场景，所以在测试的时候会发现服务器端收到的数据包的个数经常会小于包的序号，好像发生了丢包。但经过仔细分析可以发现，这种情况是因为TCP发送缓存溢出导致的丢包，也就是这个数据包根本没有发出来。也就是说，发送端发送数据过快，导致接收端缓存很快被填满，这个时候接收端会把通知窗口设置为0从而控制发送端的流量，这样新到的数据只能暂存在发送端的发送缓存中，当发送缓存溢出后，就出现了我上面提到的丢包，这个问题可以通过增大发送端缓存来缓解这个问题，
>
> ```
> socketChannel.socket().setSendBufferSize(102400);  
> ```
>
> 当然这个话题不在本文的讨论范围，如果有兴趣的同学可以参阅《TCP/IP详解卷一》中的拥塞窗口一章。
>
> 关于源码说明，源码默认是把粘包和拆包处理这一部分注释掉了，分别位于NIOTcpServer和NIOTcpClient文件中，需要测试粘包和拆包处理程序的同学需要把这一段注释给去掉。

## 同步 异步 阻塞 非阻塞

### IO 概念区分

NIO 现在已经是一个耳熟能详的名词了， 好像人人都能对所谓的 NIO ( Non-Blocking IO, 非阻塞 IO ) 发表一些如何如何提高效率的言论。 但很多东西， 追问几句就会难以自圆其说。

四个相关概念：

- 同步（Synchronous）
- 异步( Asynchronous)
- 阻塞( Blocking )
- 非阻塞( Nonblocking)

这四个概念的含义以及相互之间的区别与联系，并不如很多网络博客所写的那么简单, 通过举一些什么商店购物， 买书买报的例子就能讲清楚。

### 进程通信上下文的同步/异步， 阻塞/非阻塞

首先强调一点， 网络上的很多博文关于同步/异步， 阻塞非阻塞区别的解释其实都很经不起推敲。 例如[怎样理解阻塞非阻塞与同步异步的区别](https://www.zhihu.com/question/19732473) 这一高赞回答中 ， 有如下解释（不准确）：

> - 同步/异步关注的是消息通信机制 (synchronous communication/ asynchronous communication) 。
>   - 所谓同步，就是在发出一个调用时，在没有得到结果之前， 该调用就不返回。
>   - 异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果
> - 阻塞/非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.
>   - 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
>   - 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

粗一看， 好像**同步/ 非同步**， **阻塞/非阻塞** 是两种维度的概念， 可以分别对待， 但是稍微推敲一下就会发现上述的解释根本难以自圆其说。

- 如果**“同步”** 是发起了一个调用后， 没有得到结果之前不返回， 那它毫无疑问就是被"**阻塞**"了（**即调用进程处于 “waiting” 状态**）。
- 如果调用发出了以后就直接返回了， 毫无疑问， 这个进程没有被“**阻塞**”。

所以， 上述的解释是不准确的。 让我们看一下《操作系统概念（第九版）》中有关进程间通信的部分是如何解释的：

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003161223336.png)

翻译一下就是：

> 进程间的通信时通过 send() 和 receive() 两种基本操作完成的。具体如何实现这两种基础操作，存在着不同的设计。
> 消息的传递有`可能是**阻塞的**或**非阻塞的** -- 也被称为**同步**或**异步**的`：
>
> - 阻塞式发送（blocking send）. 发送方进程会被一直阻塞， 直到消息被接受方进程收到。
> - 非阻塞式发送（nonblocking send）。 发送方进程调用 send() 后， 立即就可以其他操作。
> - 阻塞式接收（blocking receive） 接收方调用 receive() 后一直阻塞， 直到消息到达可用。
> - 非阻塞式接受（nonblocking receive） 接收方调用 receive() 函数后， 要么得到一个有效的结果， 要么得到一个空值， 即不会被阻塞。
>
> **上述不同类型的发送方式和不同类型的接收方式，可以自由组合。**

- 也就是说， `从进程级通信的维度讨论时， 阻塞和同步（非阻塞和异步）就是一对同义词`， 且需要针对**发送方**和**接收方**作区分对待。

### 先修知识

- 用户空间和内核空间
- 进程切换
  - 系统调用（system call）
  - 中断（interrupt）
- 进程的阻塞

#### 用户空间和内核空间

操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立（一个进程的崩溃不会影响其他的进程 ， 恶意进程不能直接读取和修改其他进程运行时的代码和数据）。 因此操作系统内核**需要拥有高于普通进程的权限**， 以此来调度和管理用户的应用程序。

于是内存空间被划分为两部分，一部分为内核空间，一部分为用户空间，内核空间存储的代码和数据具有更高级别的权限。内存访问的**相关硬件**在程序执行期间会进行访问控制（ Access Control），使得用户空间的程序不能直接读写内核空间的内存。

- 有《微机原理》 课程基础同学可以 Google 搜索 DPL, CPL 这两个关键字了解硬件层面的内存访问权限控制细节

#### 进程切换

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003125150176.png)

上图展示了进程切换中几个最重要的步骤：

1. 当一个程序正在执行的过程中， 中断（interrupt） 或 系统调用（system call） 发生可以使得 CPU 的控制权会从当前进程转移到操作系统内核。
2. 操作系统内核负责保存进程 i 在 CPU 中的上下文（程序计数器， 寄存器）到 PCBiPCB_iPCBi （操作系统分配给进程的一个内存块）中。
3. 从 PCBjPCB_jPCBj 取出进程 j 的CPU 上下文， 将 CPU 控制权转移给进程 j ， 开始执行进程 j 的指令。

几个底层概念的通俗（不严谨）解释：

- 中断（interrupt）
  - CPU 微处理器有一个中断信号位， 在每个CPU时钟周期的末尾, CPU会去检测那个中断信号位是否有中断信号到达， 如果有， 则会根据中断优先级决定是否要暂停当前执行的指令， 转而去执行处理中断的指令。 （其实就是 CPU 层级的 while 轮询）
- 时钟中断( Clock Interrupt )
  - 一个硬件时钟会每隔一段（很短）的时间就产生一个中断信号发送给 CPU，CPU 在响应这个中断时， 就会去执行操作系统内核的指令， 继而将 CPU 的控制权转移给了操作系统内核， 可以由操作系统内核决定下一个要被执行的指令。
- 系统调用（system call）
  - system call 是操作系统提供给应用程序的接口。 用户通过调用 systemcall 来完成那些需要操作系统内核进行的操作， 例如硬盘， 网络接口设备的读写等。

从上述描述中， 可以看出来， 操作系统在进行进切换时，需要进行一系列的内存读写操作， 这带来了一定的开销：

- 对于一个运行着 UNIX 系统的现代 PC 来说， 进程切换至少需要花费 300 us 的时间

#### 进程阻塞

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003135833118.png)
上图展示了一个进程的不同状态：

- New。 进程正在被创建.
- Running. 进程的指令正在被执行
- Waiting. 进程正在等待一些事件的发生（例如 I/O 的完成或者收到某个信号）。
- Ready. 进程在等待被操作系统调度。
- Terminated. 进程执行完毕（可能是被强行终止的）。

我们所说的 “阻塞”是指进程在**发起了一个系统调用**（System Call） 后， 由于该系统调用的操作不能立即完成，需要等待一段时间，于是内核将进程挂起为**等待 （waiting）**状态， 以确保它不会被调度执行， 占用 CPU 资源。

- 友情提示： **在任意时刻， 一个 CPU 核心上（processor）只可能运行一个进程** 。

### I/O System Call 的阻塞/非阻塞， 同步/异步

这里再重新审视 **阻塞/非阻塞 IO** 这个概念， 其实**阻塞和非阻塞**描述的是进程的一个操作是否会使得进程转变为“等待”的状态， 但是为什么我们总是把它和 IO 连在一起讨论呢？

原因是， **阻塞**这个词是与系统调用 System Call 紧紧联系在一起的， 因为要让一个进程进入 等待（waiting） 的状态, 要么是它主动调用 wait() 或 sleep() 等挂起自己的操作， 另一种就是它调用 System Call, 而 System Call 因为涉及到了 I/O 操作， 不能立即完成， 于是内核就会先将该进程置为等待状态， 调度其他进程的运行， 等到 它所请求的 I/O 操作完成了以后， 再将其状态更改回 ready 。

操作系统内核在执行 System Call 时， CPU 需要与 IO 设备完成一系列物理通信上的交互， 其实再一次会涉及到阻塞和非阻塞的问题， 例如， 操作系统发起了一个读硬盘的请求后， 其实是向硬盘设备通过总线发出了一个请求，它即可以阻塞式地等待IO 设备的返回结果，也可以非阻塞式的继续其他的操作。 在现代计算机中，这些物理通信操作基本都是异步完成的， 即发出请求后， 等待 I/O 设备的中断信号后， 再来读取相应的设备缓冲区。 但是，大部分操作系统默认为用户级应用程序提供的都是阻塞式的系统调用 （blocking systemcall）接口， 因为阻塞式的调用，使得应用级代码的编写更容易（代码的执!行顺序和编写顺序是一致的）。

但同样， 现在的大部分操作系统也会提供非阻塞I/O 系统调用接口（Nonblocking I/O system call）。 一个非阻塞调用不会挂起调用程序， 而是会立即返回一个值， 表示有多少bytes 的数据被成功读取（或写入）。

非阻塞I/O 系统调用( nonblocking system call )的另一个替代品是 **异步I/O系统调用 （asychronous system call）**。 与非阻塞 I/O 系统调用类似，asychronous system call 也是会立即返回， 不会等待 I/O 操作的完成， 应用程序可以继续执行其他的操作， 等到 I/O 操作完成了以后，操作系统会通知调用进程（设置一个用户空间特殊的变量值 或者 触发一个 signal 或者 产生一个软中断 或者 调用应用程序的回调函数）。

此处， **非阻塞I/O 系统调用( nonblocking system call )** 和 **异步I/O系统调用 （asychronous system call）**的区别是：

- 一个**非阻塞I/O 系统调用 read()** 操作立即返回的是任何可以立即拿到的数据， 可以是完整的结果， 也可以是不完整的结果， 还可以是一个空值。
- 而**异步I/O系统调用** read（）结果必须是完整的， 但是这个操作完成的通知可以延迟到将来的一个时间点。

下图展示了同步I/O 与 异步 I/O 的区别 （非阻塞 IO 在下图中没有绘出）.
![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003191809025.png)

注意， 上面提到的 **非阻塞I/O 系统调用( nonblocking system call )** 和 **异步I/O系统调用** 都是非阻塞式的行为（non-blocking behavior）。 他们的差异仅仅是返回结果的方式和内容不同。

### 非阻塞 I/O 如何帮助服务器提高吞吐量

考虑一个**单进程**服务器程序， 收到一个 Socket 连接请求后， 读取请求中的文件名，然后读请求的文件名内容，将文件内容返回给客户端。 那么一个请求的处理流程会如下图所示。

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003193332944.png)

- R 表示读操作
- W 表示写操作
- C 表示关闭操作

在这个过程中， 我们可以看到， CPU 和 硬盘IO 的资源大部分时间都是闲置的。 此时， 我们会希望在等待 I/O 的过程中继续处理新的请求。

方案一： 多进程

- 每到达一个请求， 我们为这个请求新创建一个进程来处理。 这样， 一个进程在等待 IO 时， 其他的进程可以被调度执行， 更加充分地利用 CPU 等资源。
- 问题： 每新创建一个进程都会消耗一定的内存空间， 且进程切换也会有时间消耗， 高并发时， 大量进程来回切换的时间开销会变得明显起来。

方案二：多线程

- 和多进程方案类似，为每一个请求新建一个线程进行处理，这样做的重要区别是， 所有的线程都共享同一个进程空间
- 问题： 需要考虑是否需要为特定的逻辑使用锁。

引申问题： 一个进程中的某一个线程发起了 system call 后， 是否造成整个进程的阻塞？ 如果会， 那么多线程方案与单进程方案相比就没有明显的改善。

- 解决办法1：内核支持的线程（kenerl supported threads）
  - 操作系统内核能够感知到线程， 每一个线程都会有一个内核调用栈（kenerl stack） 和 保存CPU 寄存器下文的 table 。

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003204926305.png)

在这种方案中， 如果 CPU 是多核的， 不同的线程还可以运行在不同的 CPU processor 上。 既实现了IO 并发， 也实现了 CPU 并发。

问题： 基于内核线程编写的应用会难以移植

- 不同的操作系统对于内核线程的支持方式统而言有所差别，甚至部分操作系统甚至不支持内核级别线程， 当应用代码基于内核线程进行开发后， 就使得应用层代码与特定的操作系统产生了耦合关系， 不能随意部署
- 解决办法2： 用户支持的线程（user supported threads）
  - 内核感知不到用户线程， 每一个用户的进程拥有一个调度器， 该调度器可以感知到线程发起的系统调用， 当一个线程产生系统调用时， 不阻塞整个进程， 切换到其他线程继续运行。 当 I/O 调用完成以后， 能够重新唤醒被阻塞的线程。
  - 实现细节：
    - 应用程序基于线程库 thread libray 编写
    - 线程库中包含 “虚假的” read(), write(), accept()等系统调用。
    - 线程库中的 read(), write(), accept() 的底层实现为非阻塞系统调用（Non-blocking system call）， 调用后，由于可以立即返回， 则将特定的线程状态标记为 waiting, 调度其他的可执行线程。 内核完成了 IO 操作后， 调用线程库的回调函数， 将原来处于 waiting 状态的线程标记为 runnable.

![这里写图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20171003213317579.png)
从上面的过程可以看出，用户支持线程的解决方案基于非阻塞IO系统调用( non-blocking system call) ， 且是一种基于操作系统内核事件通知（event-driven）的解决方案， 基于这个流程, 可以引申到更为宽泛的 event-driven progreamming 话题上。 但是这里就不作赘述了。

### 总结：

1. 阻塞/非阻塞， 同步/异步的概念要注意讨论的上下文：

- 在进程通信层面， 阻塞/非阻塞， 同步/异步基本是同义词， 但是需要注意区分讨论的对象是发送方还是接收方。
  - 发送方阻塞/非阻塞（同步/异步）和接收方的阻塞/非阻塞（同步/异步） 是互不影响的。
- 在 IO 系统调用层面（ IO system call ）层面， 非阻塞IO 系统调用 和 异步IO 系统调用存在着一定的差别， 它们都不会阻塞进程， 但是返回结果的方式和内容有所差别， 但是都属于非阻塞系统调用（ non-blocing system call ）

1. 非阻塞系统调用（non-blocking I/O system call 与 asynchronous I/O system call） 的存在可以用来实现线程级别的 I/O 并发， 与通过多进程实现的 I/O 并发相比可以减少内存消耗以及进程切换的开销。

## socket

### 0. socket 简介

​       在图1中，我们没有看到Socket的影子，那么它到底在哪里呢？还是用图来说话，一目了然。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190718154523875.png)
图2

​       原来Socket在这里。
**Socket****是什么呢？**
       Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。
**你会使用它们吗？**
       前人已经给我们做了好多的事了，网络间的通信也就简单了许多，但毕竟还是有挺多工作要做的。以前听到Socket编程，觉得它是比较高深的编程知识，但是只要弄清Socket编程的工作原理，神秘的面纱也就揭开了。
       一个生活中的场景。你要打电话给一个朋友，先拨号，朋友听到电话铃声后提起电话，这时你和你的朋友就建立起了连接，就可以讲话了。等交流结束，挂断电话结束此次交谈。    生活中的场景就解释了这工作原理，也许TCP/IP协议族就是诞生于生活中，这也不一定。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190718154556909.png)      

图3

​       先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。

============================================

我们深谙信息交流的价值，那网络中进程之间如何通信，如我们每天打开浏览器浏览网页 时，浏览器的进程怎么与web服务器通信的？当你用QQ聊天时，QQ进程怎么与服务器或你好友所在的QQ进程通信？这些都得靠socket？那什么是 socket？socket的类型有哪些？还有socket的基本函数，这些都是本文想介绍的。本文的主要内容如下：

- 1、网络中进程之间如何通信？
- 2、Socket是什么？
- 3、socket的基本操作
  - 3.1、socket()函数
  - 3.2、bind()函数
  - 3.3、listen()、connect()函数
  - 3.4、accept()函数
  - 3.5、read()、write()函数等
  - 3.6、close()函数
- 4、socket中TCP的三次握手建立连接详解
- 5、socket中TCP的四次握手释放连接详解
- 6、一个例子

### 1、网络中进程之间如何通信？

本地的进程间通信（IPC）有很多种方式，但可以总结为下面4类：

- 消息传递（管道、FIFO、消息队列）
- 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）
- 共享内存（匿名的和具名的）
- 远程过程调用（Solaris门和Sun RPC）

> 但这些都不是本文的主题！我们要讨论的是网络中进程之间如何通信？首要解决的问题是如何唯一标识一个进程，否则通信无从谈起！在本地可以通过进程PID来唯一标识一个进程，但是在网络中这是行不通的。其实TCP/IP协议族已经帮我们解决了这个问题，网络层的“**ip地址**”可以唯一标识网络中的主机，而传输层的“**协议+端口**”可以唯一标识主机中的应用程序（进程）。这样利用**三元组（ip地址，协议，端口）**就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互。
>
> 使用TCP/IP协议的应用程序通常采用应用编程接口：UNIX BSD的套接字（socket）和UNIX System V的TLI（已经被淘汰），来实现网络进程之间的通信。就目前而言，几乎所有的应用程序都是采用socket，而现在又是网络时代，网络中进程通信是无处不在，这就是我为什么说“一切皆socket”。

### 2、什么是Socket？

上面我们已经知道网络中的进程是通过socket来通信的，那什么是socket呢？socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –> 读写write/read –> 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭），这些函数我们在后面进行介绍。

> ### socket一词的起源
>
> 在组网领域的首次使用是在1970年2月12日发布的文献[IETF RFC33](http://datatracker.ietf.org/doc/rfc33/)中发现的，撰写者为Stephen Carr、Steve Crocker和Vint Cerf。根据美国计算机历史博物馆的记载，Croker写道：“命名空间的元素都可称为套接字接口。一个套接字接口构成一个连接的一端，而一个连接可完全由一对套接字接口规定。”计算机历史博物馆补充道：“这比BSD的套接字接口定义早了大约12年。”

### 3、socket的基本操作

既然socket是“open—write/read—close”模式的一种实现，那么socket就提供了这些操作对应的函数接口。下面以TCP为例，介绍几个基本的socket接口函数。

#### 3.1、socket()函数

```
int socket(int domain, int type, int protocol);
```

socket函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而**socket()**用于创建一个socket描述符（socket descriptor），它唯一标识一个socket。这个socket描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。

正如可以给fopen的传入不同参数值，以打开不同的文件。创建socket的时候，也可以指定不同的参数创建不同的socket描述符，socket函数的三个参数分别为：

- domain：即协议域，又称为协议族（family）。常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。
- type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等（socket的类型有哪些？）。
- protocol：故名思意，就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议（这个协议我将会单独开篇讨论！）。

注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。

当我们调用**socket**创建一个socket时，返回的socket描述字它存在于协议族（address family，AF_XXX）空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用bind()函数，否则就当调用connect()、listen()时系统会自动随机分配一个端口。

#### 3.2、bind()函数

正如上面所说bind()函数把一个地址族中的特定地址赋给socket。例如对应AF_INET、AF_INET6就是把一个ipv4或ipv6地址和端口号组合赋给socket。

```
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

函数的三个参数分别为：

- sockfd：即socket描述字，它是通过socket()函数创建了，唯一标识一个socket。bind()函数就是将给这个描述字绑定一个名字。

- addr：一个const struct sockaddr *指针，指向要绑定给sockfd的协议地址。这个地址结构根据地址创建socket时的地址协议族的不同而不同，如ipv4对应的是：

  ```
  struct sockaddr_in {
      sa_family_t    sin_family; 
      in_port_t      sin_port;   
      struct in_addr sin_addr;   
  };
  ```

  struct in_addr {
      uint32_t       s_addr;     
  };

```
  ipv6对应的是：

```

  struct sockaddr_in6 { 
      sa_family_t     sin6_family;    
      in_port_t       sin6_port;      
      uint32_t        sin6_flowinfo;  
      struct in6_addr sin6_addr;      
      uint32_t        sin6_scope_id;  
  };

  struct in6_addr { 
      unsigned char   s6_addr[16];    
  };

```
  Unix域对应的是：

```

  struct sockaddr_un { 
      sa_family_t sun_family;                
      char        sun_path[UNIX_PATH_MAX];   
  };

- addrlen：对应的是地址的长度。

通常服务器在启动的时候都会绑定一个众所周知的地址（如ip地址+端口号），用于提供服务，客户就可以通过它来接连服务器；而客户端就不用指定，有系统自动分配一个端口号和自身的ip地址组合。这就是为什么通常服务器端在listen之前会调用bind()，而客户端就不会调用，而是在connect()时由系统随机生成一个。

> ### 网络字节序与主机字节序
>
> **主机字节序**就是我们平常说的大端和小端模式：不同的CPU有不同的字节序类型，这些字节序是指整数在内存中保存的顺序，这个叫做主机序。引用标准的Big-Endian和Little-Endian的定义如下：
>
> 　　a) Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。
>
> 　　b) Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。
>
> **网络字节序**：4个字节的32 bit值以下面的次序传输：首先是0～7bit，其次8～15bit，然后16～23bit，最后是24~31bit。这种传输次序称作大端字节序。**由于TCP/IP首部中所有的二进制整数在网络中传输时都要求以这种次序，因此它又称作网络字节序。**字节序，顾名思义字节的顺序，就是大于一个字节类型的数据在内存中的存放顺序，一个字节的数据没有顺序的问题了。
>
> 所以： 在将一个地址绑定到socket的时候，请先将主机字节序转换成为网络字节序，而不要假定主机字节序跟网络字节序一样使用的是Big-Endian。由于 这个问题曾引发过血案！公司项目代码中由于存在这个问题，导致了很多莫名其妙的问题，所以请谨记对主机字节序不要做任何假定，务必将其转化为网络字节序再 赋给socket。

#### 3.3、listen()、connect()函数

如果作为一个服务器，在调用socket()、bind()之后就会调用listen()来监听这个socket，如果客户端这时调用connect()发出连接请求，服务器端就会接收到这个请求。

int listen(int sockfd, int backlog);
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);

listen函数的第一个参数即为要监听的socket描述字，第二个参数为相应socket可以排队的最大连接个数。socket()函数创建的socket默认是一个主动类型的，listen函数将socket变为被动类型的，等待客户的连接请求。

connect函数的第一个参数即为客户端的socket描述字，第二参数为服务器的socket地址，第三个参数为socket地址的长度。客户端通过调用connect函数来建立与TCP服务器的连接。

#### 3.4、accept()函数

TCP服务器端依次调用socket()、bind()、listen()之后，就会监听指定的socket地址了。TCP客户端依次调用socket()、connect()之后就想TCP服务器发送了一个连接请求。TCP服务器监听到这个请求之后，就会调用accept()函数取接收请求，这样连接就建立好了。之后就可以开始网络I/O操作了，即类同于普通文件的读写I/O操作。

int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);

accept函数的第一个参数为服务器的socket描述字，第二个参数为指向struct sockaddr *的指针，用于返回客户端的协议地址，第三个参数为协议地址的长度。如果accpet成功，那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的TCP连接。

注意：accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept函数返回的是已连接的socket描述字。一个服务器通常通常仅仅只创建一个监听socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接受的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就被关闭。

#### 3.5、read()、write()等函数

万事具备只欠东风，至此服务器与客户已经建立好连接了。可以调用网络I/O进行读写操作了，即实现了网咯中不同进程之间的通信！网络I/O操作有下面几组：

- read()/write()
- recv()/send()
- readv()/writev()
- recvmsg()/sendmsg()
- recvfrom()/sendto()

我推荐使用recvmsg()/sendmsg()函数，这两个函数是最通用的I/O函数，实际上可以把上面的其它函数都替换成这两个函数。它们的声明如下：

```
   #include 

   ssize_t read(int fd, void *buf, size_t count);
   ssize_t write(int fd, const void *buf, size_t count);

   #include 
   #include 

   ssize_t send(int sockfd, const void *buf, size_t len, int flags);
   ssize_t recv(int sockfd, void *buf, size_t len, int flags);

   ssize_t sendto(int sockfd, const void *buf, size_t len, int flags,
                  const struct sockaddr *dest_addr, socklen_t addrlen);
   ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,
                    struct sockaddr *src_addr, socklen_t *addrlen);

   ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
   ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);
```

read函数是负责从fd中读取内容.当读成功时，read返回实际所读的字节数，如果返回的值是0表示已经读到文件的结束了，小于0表示出现了错误。如果错误为EINTR说明读是由中断引起的，如果是ECONNREST表示网络连接出了问题。

write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节 数。失败时返回-1，并设置errno变量。在网络程序中，当我们向套接字文件描述符写时有俩种可能。1)write的返回值大于0，表示写了部分或者是 全部的数据。2)返回的值小于0，此时出现了错误。我们要根据错误类型来处理。如果错误为EINTR表示在写的时候出现了中断错误。如果为EPIPE表示 网络连接出现了问题(对方已经关闭了连接)。

其它的我就不一一介绍这几对I/O函数了，具体参见man文档或者baidu、Google，下面的例子中将使用到send/recv。

#### 3.6、close()函数

在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的socket描述字，好比操作完打开的文件要调用fclose关闭打开的文件。



int close(int fd);

close一个TCP socket的缺省行为时把该socket标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为read或write的第一个参数。

注意：close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求。

### 4、socket中TCP的三次握手建立连接详解

我们知道tcp建立连接要进行“三次握手”，即交换三个分组。大致流程如下：

- 客户端向服务器发送一个SYN J
- 服务器向客户端响应一个SYN K，并对SYN J进行确认ACK J+1
- 客户端再想服务器发一个确认ACK K+1

只有就完了三次握手，但是这个三次握手发生在socket的那几个函数中呢？请看下图：

[![image](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\aHR0cHM6Ly9pbWFnZXMuY25ibG9ncy5jb20vY25ibG9nc19jb20vc2t5bmV0LzIwMTAxMi8yMDEwMTIxMjIxNTc0NzYyODYucG5n.png)](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png)

图1、socket中发送的TCP三次握手

从图中可以看出，当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。

> 总结：客户端的connect在三次握手的第二个次返回，而服务器端的accept在三次握手的第三次返回。

### 5、socket中TCP的四次握手释放连接详解

上面介绍了socket中TCP的三次握手建立过程，及其涉及的socket函数。现在我们介绍socket中的四次握手释放连接的过程，请看下图：

[![image](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\aHR0cHM6Ly9pbWFnZXMuY25ibG9ncy5jb20vY25ibG9nc19jb20vc2t5bmV0LzIwMTAxMi8yMDEwMTIxMjIxNTc0OTQ2OTMucG5n.png)](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157487616.png)

图2、socket中发送的TCP四次握手

图示过程如下：

- 某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；
- 另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；
- 一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；
- 接收到这个FIN的源发送端TCP对它进行确认。

这样每个方向上都有一个FIN和ACK。

 

6.下面给出实现的一个实例

 

首先，先给出实现的截图

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190718155008892.png)

## 五大io模式

### 1.阻塞IO模型

　　最传统的一种IO模型，即在读写数据过程中会发生阻塞现象。

　　当用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。

典型的阻塞IO模型的例子为：data = socket.read();

如果数据没有就绪，就会一直阻塞在read方法。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABAEGAAg0MKrwAUosJqimgYwgAU4xQI.png)

### 2.非阻塞IO模型

　　当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。

　　所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU。典型的非阻塞IO模型一般如下：

> while(true){
>
>    data = socket.read();
>
>    if(data!= error){
>
> ​       处理数据
>
> ​       break;
>
>    }
>
> }

　　但是对于非阻塞IO就有一个非常严重的问题，在while循环中需要不断地去询问内核数据是否就绪，这样会导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABAEGAAg7MKrwAUogfiO-QUwgAU48gI.png)

### **3.多路复用IO模型**

　　多路复用IO模型是目前使用得比较多的模型。Java NIO实际上就是多路复用IO。

　　在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

　　在Java NIO中，是通过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。

　　也许有朋友会说，我可以采用多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。

　　而多路复用IO模式，通过一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源来进行实际的读写操作。因此，多路复用IO比较适合连接数比较多的情况。

　　另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。

　　不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABAEGAAg_sKrwAUojMPt1gIwgAU4mgM.png)

### **4.信号驱动IO模型**

　　在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。这个一般用于UDP中，对TCP套接口几乎是没用的，原因是该信号产生得过于频繁，并且该信号的出现并没有告诉我们发生了什么事情

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABAEGAAglcOrwAUoqPiNiQYwgAU4lgM.png)

### **5.异步IO模型**

　　异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。

　　也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。

　　注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。简称AIO

前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，IO操作的第2个阶段都会引起用户线程阻塞，也就是内核进行数据拷贝的过程都会让用户线程阻塞。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABAEGAAgvMOrwAUoypzSBzCABTjtAg.png)

**两种高性能IO设计模式**

在传统的网络服务设计模式中，有两种比较经典的模式：

　　一种是多线程，一种是线程池。

　　对于多线程模式，也就说来了client，服务器就会新建一个线程来处理该client的读写事件，如下图所示：

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABACGAAgzsOrwAUottWq8QUwwgM4qgM.jpg)

这种模式虽然处理起来简单方便，但是由于服务器为每个client的连接都采用一个线程去处理，使得资源占用非常大。因此，当连接数量达到上限时，再有用户请求连接，直接会导致资源瓶颈，严重的可能会直接导致服务器崩溃。

　　因此，为了解决这种一个线程对应一个客户端模式带来的问题，提出了采用线程池的方式，也就说创建一个固定大小的线程池，来一个客户端，就从线程池取一个空闲线程来处理，当客户端处理完读写操作之后，就交出对线程的占用。因此这样就避免为每一个客户端都要创建线程带来的资源浪费，使得线程可以重用。

　　但是线程池也有它的弊端，如果连接大多是长连接，因此可能会导致在一段时间内，线程池中的线程都被占用，那么当再有用户请求连接时，由于没有可用的空闲线程来处理，就会导致客户端连接失败，从而影响用户体验。因此，线程池比较适合大量的短连接应用。

　　因此便出现了下面的两种高性能IO设计模式：Reactor和Proactor。

在Reactor模式中，会先对每个client注册感兴趣的事件，然后有一个线程专门去轮询每个client是否有事件发生，当有事件发生时，便顺序处理每个事件，当所有事件处理完之后，便再转去继续轮询，如下图所示：

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\ABUIABACGAAg4MOrwAUov7LMvAUw3gU46gM.jpg)

从这里可以看出，上面的五种IO模型中的多路复用IO就是采用Reactor模式。注意，上面的图中展示的 是顺序处理每个事件，当然为了提高事件处理速度，可以通过多线程或者线程池的方式来处理事件。Java NIO使用的就是这种

　　在Proactor模式中，当检测到有事件发生时，会新起一个异步操作，然后交由内核线程去处理，当内核线程完成IO操作之后，发送一个通知告知操作已完成，可以得知，异步IO模型采用的就是Proactor模式。Java AIO使用的这种，转载注明来自：<http://www.youxijishu.com/h-nd-141-2_323.html>

## epoll,select基础

### 基础

在讲解之前，我们需要先知道计算机是如何接受网络数据的。简单来讲，就是当网络数据到达网卡的时候，网卡会通过中断控制器向CPU发送中断信号，CPU接受到中断信号的时候会根据接受到的中断向量号调用提前在中段描述符表中注册好的中断处理程序，中断处理程序会保存当前正在执行的程序的上下文，然后将网卡的中的数据复制到内核缓冲区，在等待空闲的时间将内核缓冲区的数据复制到用户缓冲区中供用户进程处理。

而我们知道，对于服务端建立socket的过程如下：

> //创建socket
> int s = socket(AF_INET, SOCK_STREAM, 0);   
> //绑定
> bind(s, ...)
> //监听
> listen(s, ...)
> //接受客户端连接
> int c = accept(s, ...)
> //接收客户端数据
> recv(c, ...);
> //将数据打印出来
> printf(...)

当和客户端成功完成3次握手后，便会调用recv阻塞等待接收客户端发送过来的数据。

实际上，当某个进程A执行到创建socket语句的时候， 操作系统就会创建一个由文件系统管理的socket对象。socket包含了发送缓冲区、接收缓冲区、等待队列等。其中发送缓冲区和接收缓冲区就是我们TCP流量控制中用到的滑动窗口，而TCP本身就是全双工的，既可以发送数据，又可以接收数据，因此会有2个缓冲区。而等待队列指向的是所有等待该socket事件的进程。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-6505c2327c5bd4eb-1600592068692.webp)

image.png

当程序执行到recv的时候，操作系统会将进程A从工作队列移动到该socket的等待队列中（传个引用），进程B、C继续调度执行，A进程被阻塞

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-6505c2327c5bd4eb-1600592074728.webp)

image.png

当socket接收到数据，操作系统便会将在该socket的等待队列上的进程重新放回工作队列中，由内核调度器继续调度执行，该进程变成运行状态，继续执行代码，由于socket的接收缓冲区已有了数据，recv便可接收返回的数据。

那么当数据到来的时候，操作系统如何知道是哪一个socket呢？一个进程又是如何监听多个socket的数据呢？

因为一条TCP连接对应一个四元组，TCP首部的信息中含有接收方的端口号信息，而一个socket对应着一个端口号，因此可以根据TCP头部的信息找到对应的socket，将数据复制到socket的接收缓冲区中；而进程正是通过**IO多路复用**的形式来监听多个socket（select和epoll）。

### select原理

如下的代码中，准备一个数组fds，存放需要监视的所有socket，然后调用select，如果fds中所有的socket都没有数据，select会阻塞，直到有一个socket收到数据，select返回，唤醒进程，用户可以遍历fds，通过FD_ISSET判断哪个socket收到了数据，然后做出处理。

> int s = socket(AF_INET, SOCK_STREAM, 0);  
> bind(s, ...)
> listen(s, ...)
>
> int fds[] =  存放需要监听的socket
>
> while(1){
>     int n = select(..., fds, ...)
>     for(int i=0; i < fds.count; i++){
>         if(FD_ISSET(fds[i], ...)){
>             //fds[i]的数据处理
>         }
>     }
> }

加入进程A同时监视如下图的sock1、sock2、sock3，调用select后操作系统会将进程A分别加入这3个socket的等待队列中。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-959669cd98fdfde7.webp)

image.png

当任何一个socket收到数据后，中断处理程序唤醒线程，加入工作队列

然后A继续执行，只需遍历一遍socket列表，就可以得到就绪的socket。

但是简单的方法往往有缺点，主要是：
其一，每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。
其二，进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。
那么，有没有减少遍历的方法？有没有保存就绪socket的方法？这两个问题便是epoll技术要解决的。

补充说明： 本节只解释了select的一种情形。当程序调用select时，内核会先遍历一遍socket，如果有一个以上的socket接收缓冲区有数据，那么select直接返回，不会阻塞。这也是为什么select的返回值有可能大于1的原因之一。如果没有socket有数据，进程才会阻塞。

epoll解决了上述select低效的问题：
epoll先用epoll_create创建一个epoll对象epfd，再通过epoll_ctl将需要监视的socket添加到epfd中，最后调用epoll_wait等待数据。

int s = socket(AF_INET, SOCK_STREAM, 0);   
bind(s, ...)
listen(s, ...)

int epfd = epoll_create(...);
epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中

while(1){
    int n = epoll_wait(...)
    for(接收到数据的socket){
        //处理
    }
}

内核维护一个“就绪链表”，引用收到数据的socket，防止对socket的遍历，如下所示，收到数据的sock2和sock3会被rdlist（就绪链表所引用），进程被唤醒后，只需要获取rdlist的内容就能够知道哪些socket收到了数据。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-6505c2327c5bd4eb-1600592053968.webp)

### epoll原理和流程:

如下图所示，当某个进程调用epoll_create方法时，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll对象也是文件系统中的一员，和socket一样，它也会有等待队列。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-6c13246d41ee1320.webp)

image.png

创建eventpoll对象后，可以通过epoll_ctl添加或者删除需要监听的socket。以添加socket为例，如下图，如果通过epoll_ctl添加sock1、sock2和sock3的监视，内核会将eventpoll添加到这三个socket的等待队列中。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-1c2ebb22279cfa79.webp)

image.png

当socket收到数据后，中断程序会操作eventpoll对象，而不是直接操作进程。

当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用。如下图展示的是sock2和sock3收到数据后，中断程序让rdlist引用这两个socket。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-7b85f0d813dcb51d.webp)

所以eventpoll相当于一个中间层，位于socket和进程之间，**socket的数据通过改变eventpoll的就序列表来改变进程状态**。

假设计算机中正在运行进程A和进程B，在某时刻进程A运行到了epoll_wait语句。如下图所示，内核会将进程A放入eventpoll的等待队列中，阻塞进程。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-db84819c09d48cd8.webp)

image.png

当socket接收到数据，中断程序一方面修改rdlist，另一方面唤醒eventpoll等待队列中的进程，进程A再次进入运行状态（如下图）。也因为rdlist的存在，进程A可以知道哪些socket发生了变化。

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\13526929-b3725b604c321c1e.webp)

image.png

### 就绪列表的数据结构

就绪列表引用着就绪的socket，所以它应能够快速的插入数据。
程序可能随时调用epoll_ctl添加监视socket，也可能随时删除。当删除时，若该socket已经存放在就绪列表中，它也应该被移除。
所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll使用双向链表来实现就绪队列（对应上图的rdllist）。

### 索引结构

既然epoll将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的socket。至少要方便的添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是O(log(N))，效率较好。epoll使用了红黑树作为索引结构（对应上图的rbr）。

## select、poll、epoll的机制及其区别

> **1、select**
>
> ​      同步多路IO复用
>
> ​     ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190527213148418.png)
>
> 时间复杂度:O(n)
>
> fd_set(监听的端口个数)：32位机默认是1024个，64位机默认是2048。
>
> **缺点**：
>
> ​        （1）单进程可以打开fd有限制；
>
> ​        （2）对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低；
>
> ​        （2）用户空间和内核空间的复制非常消耗资源；
>
> **2、poll**
>
> ​      同步多路IO复用
>
> ​      调用过程和select类似
>
> ​      时间复杂度:O(n)
>
> ​      其和select不同的地方：采用**链表**的方式替换原有fd_set数据结构,而使其**没有连接数的限制**。
>
> **3、epoll**
>
> ​      同步多路IO复用      
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190527231438974.png)
>
> 时间复杂度:O(1)
>
> **epoll的工作方式**
>
> epoll的两种工作方式：1.水平触发（LT）2.边缘触发（ET） 
> LT模式：若就绪的事件一次没有处理完要做的事件，就会一直去处理。即就会将没有处理完的事件继续放回到就绪队列之中（即那个内核中的链表），一直进行处理。 
> ET模式：就绪的事件只能处理一次，若没有处理完会在下次的其它事件就绪时再进行处理。而若以后再也没有就绪的事件，那么剩余的那部分数据也会随之而丢失。 
> 由此可见：ET模式的效率比LT模式的效率要高很多。只是如果使用ET模式，就要保证每次进行数据处理时，要将其处理完，不能造成数据丢失，这样对编写代码的人要求就比较高。 
> 注意：ET模式只支持非阻塞的读写：为了保证数据的完整性。

## 五  在浏览器中输入url地址 ->> 显示主页的过程(面试常客)

百度好像最喜欢问这个问题。

> 打开一个网页，整个过程会使用哪些协议？

图解（图片来源：《图解HTTP》）：

<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url输入到展示出来的过程.jpg" style="zoom:50%;" />

> 上图有一个错误，请注意，是OSPF不是OPSF。 OSPF（Open Shortest Path Fitst，ospf）开放最短路径优先协议,是由Internet工程任务组开发的路由选择协议

> ### 1、输入网址
>
> 当你开始输入网址比如www.cnblogs.com时游览器就可以在书签或者历史记录里面去搜索相关的网址推荐给你。
>
> ### 2、游览器查找域名的IP地址
>
> ① 请求发起后，游览器首先会解析这个域名，首先它会查看本地硬盘的 hosts 文件，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。
>
> ② 如果在本地的 hosts 文件没有能够找到对应的 ip 地址，浏览器会发出一个 DNS请求到本地DNS(域名分布系统)服务器 。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。
>
> ③查询你输入的网址的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果，此过程是递归的方式进行查询。如果没有，本地DNS服务器还要向DNS根服务器进行查询
>
> ④根DNS服务器没有记录具体的域名和IP地址的对应关系，而是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。这种过程是迭代的过程
>
> ⑤本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址
>
> ⑥最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\1171046-20171226173034151-855747573.jpg)
>
> ### 3、建立TCP链接
>
> 在拿到域名对应的IP地址后，会以随机端口（1024~~65535）向WEB服务器程序80端口发起TCP的连接请求，这个连接请求进入到内核的TCP/IP协议栈（用于识别该连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终到达WEB程序，最终建立了TCP/IP的连接，对于客户端与服务器的TCP链接，必然要说的就是『三次握手』。
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\1171046-20190409190539159-883745097.png)
>
> 　　　　　　　　　　三次握手
>
> 客户端发送一个带有SYN标志的数据包给服务端，服务端收到后，回传一个带有SYN/ACK标志的数据包以示传达确认信息，最后客户端再回传一个带ACK标志的数据包，代表握手结束，连接成功。
>
> 通俗化之后就是：
>
> 客户端：老弟我要跟你链接
>
> 服务端：好的，同意了
>
> 客户端：好嘞
>
> ### 4、游览器向WEB服务器发起Http请求
>
> 建立TCP连接之后，发起HTTP请求，请求一般分为三部分
>
> 请求方法URI协议/版本
>
> 请求头(Request Header)
>
> 请求正文
>
> 下面是一个完整的请求
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20180519235118178.png)
>
> 详细的就不描述了，网上很多说明的。
>
> ### 5、服务器端处理
>
> 服务器端收到请求后的由web服务器（准确说应该是http服务器）处理请求，诸如Apache、Ngnix、IIS等。web服务器解析用户请求，知道了需要调度哪些资源文件，再通过相应的这些资源文件处理用户请求和参数，并调用数据库信息，最后将结果通过web服务器返回给浏览器客户端。
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\1171046-20190409191054591-1163748805.png)
>
> ### 6、关闭TCP链接
>
> 为了避免服务器与客户端双方的资源占用和损耗，当双方没有请求或响应传递时，任意一方都可以发起关闭请求。与创建TCP连接的3次握手类似，关闭TCP连接，需要4次握手。
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\1171046-20190409191208891-688664454.png)
>
> 上图可以通俗化：
>
> 客户端：老弟，我这边没数据要传了，咱们关闭链接吧
>
> 服务端：好的，接收到了，我看看我这边还有没有要传的
>
> 服务端：我这边也没有了，关闭吧
>
> 客户端：好嘞
>
> ### 7、游览器解析资源
>
> 对于获取到的HTML、CSS、JS、图片等等资源。
>
> 浏览器通过解析HTML，生成DOM树，解析CSS，生成CSS规则树，然后通过DOM树和CSS规则树生成渲染树。渲染树与DOM树不同，渲染树中并没有head、display为none等不必显示的节点。
>
> 在解析CSS的同时，可以继续加载解析HTML，但在解析执行JS脚本时，会停止解析后续HTML，这就会出现阻塞问题，关于JS阻塞相关问题，这里不过多阐述,后面会单独开篇讲解。
>
> ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\161bb3c9b220f8cb)
>
> 　　　　　　　　　　webkit渲染流程
>
> ### 8、游览器布局渲染
>
> 根据渲染树布局，计算CSS样式，即每个节点在页面中的大小和位置等几何信息。HTML默认是流式布局的，CSS和js会打破这种布局，改变DOM的外观样式以及大小和位置。这时就要提到两个重要概念：repaint和reflow。
>
> ##### repaint：屏幕的一部分重画，不影响整体布局，比如某个CSS的背景色变了，但元素的几何尺寸和位置不变。
>
> ##### reflow： 意味着元件的几何尺寸变了，我们需要重新验证并计算渲染树。是渲染树的一部分或全部发生了变化。这就是Reflow，或是Layout。
>
> 有些情况下，比如修改了元素的样式，浏览器并不会立刻 reflow 或 repaint 一次，而是会把这样的操作积攒一批，然后做一次 reflow，这又叫异步 reflow 或增量异步 reflow。
> 有些情况下，比如 resize 窗口，改变了页面默认的字体等。对于这些操作，浏览器会马上进行 reflow。

## 六 状态码

![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/状态码.png)

## 七 各种协议与HTTP协议之间的关系

一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。

图片来源：《图解HTTP》

![各种协议与HTTP协议之间的关系](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/各种协议与HTTP协议之间的关系.png)

## 八  HTTP长连接,短连接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

Connection:keep-alive

```
在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。** 

—— [《HTTP长连接、短连接究竟是什么？》](https://www.cnblogs.com/gotodsp/p/6366163.html)

## 九 HTTP是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP  协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

**Cookie 被禁用怎么办?**

最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

![HTTP是无状态协议](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HTTP是无状态的.png)

## 十 Cookie的作用是什么?和Session有什么区别？

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

 **Cookie 一般用来保存用户信息** 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

## 十一 HTTP 1.0和HTTP 1.1的主要区别是什么?

> 这部分回答引用这篇文章 <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?> 的一些内容。

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

1. **长连接** : **在HTTP/1.0中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1起，默认使用长连接** ,默认开启Connection： keep-alive。 **HTTP/1.1的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
2. **错误状态响应码** :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
3. **缓存处理** :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
4. **带宽优化及网络连接的使用** :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

## 十二 URI和URL的区别是什么?

- URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。
- URL(Uniform Resource Location) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## 十三 HTTP 和 HTTPS 的区别？

1. **端口** ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
2. **安全性和资源消耗：** HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。
   - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；
   - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。

## 建议

非常推荐大家看一下 《图解HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。

## 参考

- [https://blog.csdn.net/qq_16209077/article/details/52718250](https://blog.csdn.net/qq_16209077/article/details/52718250)
- [https://blog.csdn.net/zixiaomuwu/article/details/60965466](https://blog.csdn.net/zixiaomuwu/article/details/60965466)
- [https://blog.csdn.net/turn__back/article/details/73743641](https://blog.csdn.net/turn__back/article/details/73743641)
- <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?>
```